{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Weather Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules imported\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tkr\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cbook as cbook\n",
    "import time\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, sum, avg, udf, to_timestamp, date_trunc\n",
    "from pyspark.sql.functions import year, month, hour, dayofweek\n",
    "from pyspark.sql.functions import round, concat, col, lit\n",
    "\n",
    "from pyspark.sql.types import FloatType, StructType, IntegerType, StringType, DoubleType, StructField, TimestampType, DateType\n",
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "import random\n",
    "\n",
    "spark1 = SparkSession.builder.appName(\"CB\").getOrCreate()\n",
    "\n",
    "import datetime as dt\n",
    "print(\"modules imported\")\n",
    "\n",
    "randomSeed = 1984\n",
    "\n",
    "pathWeather = \"/users/sajudson/Dropbox/WPI/DS504/project/weather/\"\n",
    "pathData = \"/users/sajudson/Dropbox/WPI/DS504/project/data/\"\n",
    "pathFigure = \"/users/sajudson/Dropbox/WPI/DS504/project/figures/\"\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use NYC weather data for both data sets\n",
    "weatherRaw = \"NYC\"+'weatherRaw'\n",
    "weatherFeatures = \"NYC\"+'weatherFeatures'\n",
    "weather_file_type = 'csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather\n",
    "\n",
    " - Define Schema of weather data file\n",
    " - Load weather data into a dataframe,\n",
    " - Convert date string to timestamp,\n",
    " - Remove uneeded columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather file loaded 2.4327681064605713\n",
      "time stamps converted, extra columns dropped 3.6369149684906006\n",
      "+-----+--------+------------+-----------+-------------------+\n",
      "| temp|humidity|total_precip|cloud_cover|           datetime|\n",
      "+-----+--------+------------+-----------+-------------------+\n",
      "|61.12|    70.0|         0.0|      100.0|2015-10-01 00:00:00|\n",
      "|60.11|    69.0|         0.0|      100.0|2015-10-01 01:00:00|\n",
      "|58.99|    71.0|         0.0|      100.0|2015-10-01 02:00:00|\n",
      "|57.68|    74.0|         0.0|      100.0|2015-10-01 03:00:00|\n",
      "|56.46|    75.0|         0.0|      100.0|2015-10-01 04:00:00|\n",
      "|55.48|    76.0|         0.0|      100.0|2015-10-01 05:00:00|\n",
      "|54.69|    75.0|         0.0|      100.0|2015-10-01 06:00:00|\n",
      "|54.62|    64.0|         0.0|      100.0|2015-10-01 07:00:00|\n",
      "| 54.8|    63.0|         0.0|      100.0|2015-10-01 08:00:00|\n",
      "|55.72|    62.0|         0.0|      100.0|2015-10-01 09:00:00|\n",
      "|57.07|    60.0|         0.0|      100.0|2015-10-01 10:00:00|\n",
      "|58.15|    59.0|         0.0|      100.0|2015-10-01 11:00:00|\n",
      "| 58.9|    59.0|         0.0|      100.0|2015-10-01 12:00:00|\n",
      "|59.64|    59.0|         0.0|      100.0|2015-10-01 13:00:00|\n",
      "|60.11|    59.0|         0.0|      100.0|2015-10-01 14:00:00|\n",
      "|60.42|    59.0|         0.0|      100.0|2015-10-01 15:00:00|\n",
      "|60.54|    60.0|         0.0|      100.0|2015-10-01 16:00:00|\n",
      "|60.61|    60.0|         0.0|      100.0|2015-10-01 17:00:00|\n",
      "|60.42|    62.0|         0.0|      100.0|2015-10-01 18:00:00|\n",
      "|60.22|    63.0|         0.0|      100.0|2015-10-01 19:00:00|\n",
      "+-----+--------+------------+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[temp: double, humidity: double, total_precip: double, cloud_cover: double, datetime: timestamp]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0= time.time()\n",
    "weatherDataFileName = 'weather_nyc_metblue'\n",
    "weatherDataFileExt = \".csv\"\n",
    "\n",
    "#create weather schema\n",
    "\n",
    "\n",
    "weatherSchema1 = StructType([StructField('year', IntegerType(), False),\n",
    "                            StructField('month', IntegerType(), False),\n",
    "                            StructField('day', IntegerType(), False),\n",
    "                            StructField('hour', IntegerType(), False),\n",
    "                            StructField('minute', IntegerType(), False),\n",
    "                            StructField('temp', DoubleType(), False),\n",
    "                            StructField('humidity', DoubleType(), True),\n",
    "                            StructField('total_precip', DoubleType(), True),\n",
    "                            StructField('snow', DoubleType(), True),\n",
    "                            StructField('cloud_cover', DoubleType(), True),\n",
    "                            StructField('wind_speed', DoubleType(), True),\n",
    "                            StructField('wind_direction', DoubleType(), True),\n",
    "                            StructField('wind_gust', DoubleType(), True),\n",
    "                           ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"true\"\n",
    "#delimiter = \",\"\n",
    "delimiter = \";\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "weather = spark1.read.format(weather_file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .schema(weatherSchema1) \\\n",
    "  .load(pathWeather+weatherDataFileName+weatherDataFileExt\n",
    ")\n",
    "print(\"weather file loaded\",time.time()-t0)\n",
    "#convert dt_iso into spark timestamp\n",
    "@udf('string')\n",
    "def trimDateTimeUTC(d):\n",
    "    return (d[:-10])\n",
    "\n",
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "dateConcat = concat(col(\"year\"), lit(\"-\"), col(\"month\"), lit(\"-\"), col('day'))\n",
    "timeConcat = concat(col(\"hour\"), lit(\":\"), col(\"minute\"), lit(':00'))\n",
    "datetimeConcat = concat(dateConcat,lit(\" \"),timeConcat)\n",
    "\n",
    "weather = weather.withColumn(\"datetime\", to_timestamp(datetimeConcat,\"yyyy-MM-dd HH:mm:ss\").cast(\"timestamp\"))\n",
    "#weather = weather.withColumn(\"temp\", round(weather.temp-273.15,3))\n",
    "#remove extraneous weather features\n",
    "\n",
    "weatherDropFeatures1 =['year','month','day','hour','minute','wind_gust','wind_speed','snow','wind_direction'\n",
    "                     ]\n",
    "\n",
    "weather = weather.select([column for column in weather.columns if column not in weatherDropFeatures1])\n",
    "print(\"time stamps converted, extra columns dropped\",time.time()-t0)\n",
    "weather.show()\n",
    "weather.cache()\n",
    "\n",
    "#dates = (\"2015-05-12\",  \"2015-05-13\")\n",
    "#date_from, date_to = [to_timestamp(lit(s)).cast(TimestampType()) for s in dates]\n",
    "\n",
    "#weatherrange = weather.where((weather.datetime >= date_from) & (weather.datetime <= date_to))\n",
    "#weatherrange.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6012887954711914\n",
      "+-------+------------------+-----------------+-------------------+------------------+\n",
      "|summary|              temp|         humidity|       total_precip|       cloud_cover|\n",
      "+-------+------------------+-----------------+-------------------+------------------+\n",
      "|  count|             26304|            26304|              26304|             26304|\n",
      "|   mean| 55.70662902980582|69.73696015815085|0.11632831508515679| 53.49331660583943|\n",
      "| stddev|18.188485165737887|18.09230770784709| 0.5428439737579306|45.858469289829046|\n",
      "|    min|             -1.11|             22.0|                0.0|               0.0|\n",
      "|    max|             98.41|            100.0|               14.3|             100.0|\n",
      "+-------+------------------+-----------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weatherFilename = weatherFeatures + \".\"+weather_file_type\n",
    "\n",
    "t0= time.time()\n",
    "weather.write.csv(pathWeather+weatherFilename, mode=\"overwrite\", header=True, sep=\",\")\n",
    "print(time.time()-t0)\n",
    "\n",
    "\n",
    "weather.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-------------------+------------------+\n",
      "|summary|              temp|         humidity|       total_precip|       cloud_cover|\n",
      "+-------+------------------+-----------------+-------------------+------------------+\n",
      "|  count|             26304|            26304|              26304|             26304|\n",
      "|   mean| 55.70662902980582|69.73696015815085|0.11632831508515679| 53.49331660583943|\n",
      "| stddev|18.188485165737887|18.09230770784709| 0.5428439737579306|45.858469289829046|\n",
      "|    min|             -1.11|             22.0|                0.0|               0.0|\n",
      "|    max|             98.41|            100.0|               14.3|             100.0|\n",
      "+-------+------------------+-----------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weatherFeatureSchema = StructType([StructField('temp', DoubleType(), False),\n",
    "                            StructField('humidity', DoubleType(), True),\n",
    "                            StructField('total_precip', DoubleType(), True),\n",
    "                            StructField('cloud_cover', DoubleType(), True),                 \n",
    "                            StructField('datetime', TimestampType(), True)\n",
    "                           ])\n",
    "\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "weather2 = spark1.read.format(weather_file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .schema(weatherFeatureSchema) \\\n",
    "  .load(pathWeather+weatherFilename)\n",
    "\n",
    "weather2.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
